{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(add comparison for MSE)\n",
    "\n",
    "### Cross-entropy\n",
    "<center>**ELI5: One of these things is not like the other!**</center>\n",
    "\n",
    "![One of these things is different](http://steadfastlutherans.org/wp-content/uploads/2014/09/SesameStreet-OneThingDoesntBelong.jpg)\n",
    "<center>*The word of the day is Kullback-Leibler divergence!*</center>\n",
    "\n",
    "Even though each fireman's hat is slightly different (orientation, lighting, etc.) they still have high *mutual information*. If you built a \"fireman hat encoder\", you could assume some standard things about fireman hats (shape, color, etc). Then, you only need to encode the information which makes each individual hat slightly different. The sparkly hat has less mutual information, which means if you used your \"fireman hat encoder\" to try to encode the sparkle hat, you would need a lot MORE information, since you deviate greatly from the prototypical fireman hat. \n",
    "\n",
    "The divergence between one fireman hat and the next is low. The divergence between any given fireman hat and the sparkle hat is high. If we wish to build a fireman/sparkle hat classifier, we do not want to be too far from either, or else performance degrades. You want something in the middle, in this case, you encode what makes a sparkle hat different from a fireman hat, and vice-versa. The general goal of cross-entropy is to minimize the divergence to all categories.\n",
    "\n",
    "##### Encoding Scheme 1:\n",
    "Fireman hat = (generic fireman encoding) + (unique aspects of individual hat) ==> **low divergence** \n",
    "<br>Sparkle hat = (generic fireman encoding) - (everything different between generic fireman and sparkle) + (unique aspects of individual hat) ==> **very high divergence** \n",
    "<br>**Average divergence == pretty high**\n",
    "\n",
    "##### Encoding Scheme 2:\n",
    "Fireman hat = (generic hat) + (difference between generic and fireman) + (unique aspects of individual hat) ==> **moderate divergence**\n",
    "<br>Sparkle hat = (generic hat) + (difference between generic and sparkle) + (unique aspects of individual hat) ==> **moderate divergence**\n",
    "<br>**Average divergence == moderate == less than scheme 1** (totally not quantitative)\n",
    "\n",
    "[More information theory coolness from colah's blog](http://colah.github.io/posts/2015-09-Visual-Information/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
